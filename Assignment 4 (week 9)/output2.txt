# hyperparameters
batch_size = 64 # how many independent sequences will we process in parallel?
block_size = 256 # what is the maximum context length for predictions?
max_iters = 1000
eval_interval = 50
learning_rate = 3e-4
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("Using device ",device)
eval_iters = 200
n_embd = 96
n_head = 6
n_layer = 6
dropout = 0.2
# ------------

0.7018 M parameters
step 0: train loss 3.6539, val loss 3.6549
step 50: train loss 2.5582, val loss 2.5607
step 100: train loss 2.2573, val loss 2.2597
step 150: train loss 2.0624, val loss 2.0696
step 200: train loss 1.8650, val loss 1.8743
step 250: train loss 1.6517, val loss 1.6634
step 300: train loss 1.2904, val loss 1.3026
step 350: train loss 0.6873, val loss 0.6927
step 400: train loss 0.4708, val loss 0.4766
step 450: train loss 0.4014, val loss 0.4041
step 500: train loss 0.3791, val loss 0.3828
step 550: train loss 0.3679, val loss 0.3701
step 600: train loss 0.3623, val loss 0.3655
step 650: train loss 0.3542, val loss 0.3575
step 700: train loss 0.3542, val loss 0.3573
step 750: train loss 0.3492, val loss 0.3522
step 800: train loss 0.3470, val loss 0.3485
step 850: train loss 0.3455, val loss 0.3483
step 900: train loss 0.3438, val loss 0.3471
step 950: train loss 0.3424, val loss 0.3447
step 999: train loss 0.3421, val loss 0.3451

Come here Yumy apple
I make mess I jump
I found it No nap
Where ball More bubbles
Shoes on
Uh oh spill Uh oh spill
Uh oh spill I run fast
Big No mine Where ball
More more I found it
More more I dance
I wash hands Mama I want play with big red ball outside More
Saw big fluffy ddoggy at ppad it
I love you I jumpp
Help me please I hide
I want that Big hug
I tired Come here
I make me ake mess
No nap Daddy read me dinosaur book before bed
I love you Look moon
No touch Come here
I did it No touch
Shoe
Time taken =  572.1035444736481 s